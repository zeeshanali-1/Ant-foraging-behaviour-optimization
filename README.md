Optimization of ant foraging behaviour in a grid environment.

The objective is to develop a Markov Decision Process framework for optimizing ant foraging behavior in a simulated grid environment through reward-based learning algorithms. We're tasked with implementing and analyzing Markov Decision Processes (MDPs) using policy iteration and value iteration algorithms on a grid-world environment.
Key points:
•	Environment: A 4x4 grid with specific start, goal, and reward structure.
•	Actions: Up, down, left, right.
•	Goal: Reach the top-left corner from the bottom-left corner.
•	Algorithms: Policy iteration and value iteration.
•	Analysis:
          o	Impact of discount factor (beta) on policy.
          o	Effect of reward structure changes on policies.
          o	Extending the grid to 5x5 and comparing algorithm performance.

We followed these steps to get the results:

1.	Implement the Grid World Environment
2.  Implement Policy Iteration
3.  Implement Value Iteration
4.  Conduct Experiments with various dicount factors and modifying reward structure.
5.  Plot policies as arrows on the grid and plot value functions for better understanding.
